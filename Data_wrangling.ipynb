{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDR data processing\n",
    "\n",
    "## Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import\n",
    "\n",
    "We first import the data. Put in the dataset path into `dataset_path` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path(r\"C:\\Users\\GOIYF\\OneDrive - Bayer\\Personal Data\\RiskHunt3R\\SDR_HuSa_dashboard - hypertrophy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\GOIYF\\\\OneDrive - Bayer\\\\Personal Data\\\\RiskHunt3R\\\\SDR_HuSa_dashboard - hypertrophy.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv(dataset_path, header=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of observation metadata\n",
    "\n",
    "This assumes the observation metadata is collected in the first three rows. It starts by taking the third row, in which the dose and compound data is stored. THen it adds the first row to it, as it assumes that contains the sex of the animal.\n",
    "\n",
    "**Note:** we take here and below in the data section the columns 8::2 (so every second column from the 8th one on); this means we focus on only the percentage of the affected animals, and not the absolute numbers. If you wish to extract different values, change this value here and below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pandas.DataFrame([[x[0], x[1], \" \".join(x[2:])] for x in data.loc[2, 8::2].str.split(\" \")], columns=(\"Dose\", \"Unit\", \"Compound\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a perfect world all the entries would have a general structure `dose unit compound`. This is not the case.\n",
    "\n",
    "In the cases where we have weird formatting we follow up with the following assumptions:\n",
    "- if we split by `;` the last entry will be the compound name\n",
    "- the unit is included in the string and is either `mg/kg`, `ug/kg`, `PPM`, or `ppm`\n",
    "- where the strings contain `;` this is also a delimiter for the dose, and is thus contained also in that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = numpy.where(~metadata.loc[:,\"Unit\"].isin((\"mg/kg\", \"PPM\", \"ppm\")))[0]\n",
    "for i in indices:\n",
    "    cpd_txt = metadata.loc[i, \"Compound\"]\n",
    "    cpd = cpd_txt.split(\";\")[-1]\n",
    "    \n",
    "    if \"mg/kg\" in cpd_txt:\n",
    "        unit = 'mg/kg'\n",
    "    elif \"ug/kg\" in cpd_txt:\n",
    "        unit = \"ug/kg\"\n",
    "    elif \"PPM\" in cpd_txt or \"ppm\" in cpd_txt:\n",
    "        unit = \"PPM\"\n",
    "    else:\n",
    "        unit = \"\"\n",
    "    \n",
    "    metadata.at[i, \"Compound\"] = cpd\n",
    "    if unit:\n",
    "        metadata.at[i, \"Unit\"] = unit\n",
    "    \n",
    "    if metadata.loc[i, \"Dose\"]:\n",
    "        metadata.at[i, \"Dose\"] = metadata.loc[i, \"Dose\"].split(\";\")[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated above, in the last step we add the information on the sex. Here the observed values are `M`, `F`, `Male` and `Female`. We convert the last two into their single letter counterpart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"Sex\"] = data.loc[0, 8::2].tolist()\n",
    "metadata[\"Sex\"] = metadata[\"Sex\"].str[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of study metadata\n",
    "\n",
    "Additional metadata on the study performed is collected in the first 5 columns of the data matrix. We take these into a `study_metadata` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_metadata = data.loc[4:, :4]\n",
    "study_metadata.columns = data.loc[3, :4].tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of data matrix\n",
    "\n",
    "As above, we take only every second column from the 8th on. Next, we make sure that column names are the same as the indices in the `metadata` so we can have an easy referencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdata = data.loc[4:, 8::2]\n",
    "subdata.columns = metadata.index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the data\n",
    "In this next cell we go through every row in the study metadata. In the data matrix we check then every column that has a value (as there can be multiple values available per study). We aggregate the values from all three DataFrames into a single list of lists, which is then transformed into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = [(\"Compound\", \"Study ID\", \"Phase Name\", \"Result Raw\", \"Dose\", \"Dose-unit\", \"Sex\", \"Severity\", \"Affected\")]\n",
    "for i in study_metadata.index:\n",
    "    for j in subdata.loc[i, ~subdata.loc[i].isna()].index:\n",
    "        final_data.append([\n",
    "            metadata.loc[j, \"Compound\"],\n",
    "            study_metadata.loc[i, \"study_id\"],\n",
    "            study_metadata.loc[i, \"phase_name\"],\n",
    "            study_metadata.loc[i, \"result_raw\"],\n",
    "            metadata.loc[j, \"Dose\"],\n",
    "            metadata.loc[j, \"Unit\"],\n",
    "            metadata.loc[j, \"Sex\"],\n",
    "            study_metadata.loc[i, \"severity\"],\n",
    "            subdata.loc[i, j]\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = pandas.DataFrame(final_data[1:], columns=final_data[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleanup\n",
    "\n",
    "We strip the trailing whitespaces, regularize the compound and study names (by substituting spaces for `-` and using all capital letters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data[\"Compound\"] = processed_data[\"Compound\"].str.upper().str.replace(r'([A-Z]+)\\s*[0-9]', r'\\1-', regex=True)\n",
    "processed_data[\"Study ID\"] = processed_data[\"Study ID\"].str.upper().str.replace(r'([A-Z]+)\\s*[0-9]', r'\\1-', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data[\"Phase Name\"] = processed_data[\"Phase Name\"].str.strip()\n",
    "processed_data[\"Result Raw\"] = processed_data[\"Result Raw\"].str.strip()\n",
    "processed_data[\"Dose\"] = processed_data[\"Dose\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_02 = defaultdict(list)\n",
    "severities = processed_data[\"Severity\"].unique()\n",
    "for (compound, study, phase, sex, result, dose), subset in processed_data.groupby([\"Compound\", \"Study ID\", \"Phase Name\", \"Sex\", \"Result Raw\", \"Dose\"]):\n",
    "    processed_data_02[\"Compound\"].append(compound)\n",
    "    processed_data_02[\"Study ID\"].append(study)\n",
    "    processed_data_02[\"Phase Name\"].append(phase)\n",
    "    processed_data_02[\"Result Raw\"].append(result)\n",
    "    processed_data_02[\"Dose\"].append(dose)\n",
    "    processed_data_02[\"Dose-unit\"].append(subset[\"Dose-unit\"].values[0])\n",
    "    processed_data_02[\"Sex\"].append(sex)\n",
    "\n",
    "    # We make sure we keep all the values - if we have duplicates, they will get concatenated with ; as a separator\n",
    "    for severity in severities:\n",
    "        processed_data_02[severity].append(\"; \".join(subset.loc[subset[\"Severity\"] == severity, \"Affected\"]))\n",
    "    \n",
    "    # We mark the row for duplicate values for easier downstream analysis\n",
    "    processed_data_02[\"Duplicated\"].append(subset.duplicated(subset=\"Severity\", keep=\"first\").any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_02 = pandas.DataFrame(processed_data_02)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_02.to_csv(str(dataset_path).replace(\".\", \"_processed.\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e2a391089ec15c2228f2e9693fa2286dfab69fb2cc471869b2baee25e2252e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
